# Task 1 赛题理解

## 预测指标

#### 分类算法常见的评估指标如下：

1、混淆矩阵（Confuse Matrix）

- （1）若一个实例是正类，并且被预测为正类，即为真正类TP(True Positive )
- （2）若一个实例是正类，但是被预测为负类，即为假负类FN(False Negative )
- （3）若一个实例是负类，但是被预测为正类，即为假正类FP(False Positive )
- （4）若一个实例是负类，并且被预测为负类，即为真负类TN(True Negative )

2、准确率（Accuracy）
准确率是常用的一个评价指标，但是不适合样本不均衡的情况。
$$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$

**意义：你需要把黑的说成是黑的白的说成是白的，你说对的概率是多少，就是你的准确率。**

3、精确率（Precision）
又称查准率，正确预测为正样本（TP）占预测为正样本(TP+FP)的百分比。
$$Precision = \frac{TP}{TP + FP}$$

**意义：目前我只关心正样本，这才是我的业务，你告诉我在正样本中有多少是对的呢？**

4、召回率（Recall）
又称为查全率，正确预测为正样本（TP）占正样本(TP+FN)的百分比。
$$Recall = \frac{TP}{TP + FN}$$

**意义：我的目的是找到尽量多的正的啊，你找的这些虽说是有写正的，但你漏掉了多少呢？比如你现在找到所有的正的样本不能低于90%吧！**

5、F1 Score
精确率和召回率是相互影响的，精确率升高则召回率下降，召回率升高则精确率下降，如果需要兼顾二者，就需要精确率、召回率的结合F1 Score。
$$F1-Score = \frac{2}{\frac{1}{Precision} + \frac{1}{Recall}}$$

**意义：兼顾两者的一个分**

6、P-R曲线（Precision-Recall Curve）
P-R曲线是描述精确率和召回率变化的曲线

自己的问题：为什么他们两是一个trade off呢？

**意义：我的感觉就是对于有些案例，你的模型在判断的过程中你是肯定确定，这个样本是正的还是负的，这是属于极端的情况，就没什么决策的难度。另外呢，有些情况下这个模型处理比较模糊了，模棱两可了，这时候你改变你的阈值的时候，虽然你可以降低你的阈值，这样你就可以尽可能的把所有的样本都找出来，但是同时的，你也会把一些负的样本认做是正的，这是找全所有正样本的一个代价。相反的你可以提高你的阈值，这样那些模棱两可的区域你就不需要涉及了，这样也许你找到的正的都是真实的正的。但是你的一个代价就是有些潜在的用户你放弃了去搜索，去探寻，这样的商机和市场你就白白浪费了，在用户量覆盖的一个策略中你就比较尴尬了。不能够完成。所以这是一个trade off。**

7、ROC（Receiver Operating Characteristic）

- ROC空间将假正例率（FPR）定义为 X 轴，真正例率（TPR）定义为 Y 轴。

TPR：在所有实际为正例的样本中，被正确地判断为正例之比率。
$$TPR = \frac{TP}{TP + FN}$$

FPR：在所有实际为负例的样本中，被错误地判断为正例之比率。

$$FPR = \frac{FP}{FP + TN}$$

- **TPRate（真阳率）的意义是所有真实类别为1的样本中，预测类别为1的比例。**
- **FPRate（伪阳率）的意义是所有真实类别为0的样本中，预测类别为1的比例。**

**意义：我们希望的是真实类别为1的样本中被预测为1的比例，要大于真实为0的样本中预测为0的比例。**

**最理想的情况下，既没有真实类别为1而错分为0的样本——TPRate一直为1，也没有真实类别为0而错分为1的样本——FP rate一直为0，AUC为1，这便是AUC的极大值。**

8、AUC(Area Under Curve)
AUC（Area Under Curve）被定义为	ROC曲线	下与坐标轴围成的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。AUC越接近1.0，检测方法真实性越高;等于0.5时，则真实性最低，无应用价值。

#### 对于金融风控预测类常见的评估指标如下:

1、KS(Kolmogorov-Smirnov)
K-S曲线与ROC曲线类似，不同在于

- ROC曲线将真正例率和假正例率作为横纵轴
- K-S曲线将真正例率和假正例率都作为纵轴，横轴则由选定的阈值来充当。
  公式如下：
  $$KS=max(TPR-FPR)$$
  KS不同代表的不同情况，一般情况KS值越大，模型的区分能力越强，但是也不是越大模型效果就越好，如果KS过大，模型可能存在异常，所以当KS值过高可能需要检查模型是否过拟合。以下为KS值对应的模型情况，但此对应不是唯一的，只代表大致趋势。
- KS值<0.2,一般认为模型没有区分能力。
- KS值[0.2,0.3],模型具有一定区分能力，勉强可以接受
- KS值[0.3,0.5],模型具有较强的区分能力。
- KS值大于0.75，往往表示模型有异常。
  2、ROC
  3、AUC





## 赛题流程

![](https://img-blog.csdnimg.cn/2020090509170561.png)

