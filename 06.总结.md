# 模型训练与验证
1. 了解模型训练、预测及线下验证
2. 掌握机器学习常用模型
3. 利用工具对资金流入流出数据进行训练、验证及预测

##  模型训练、预测及线下验证

![](/Users/mxchip/Desktop/截屏2020-08-26 上午11.58.43.png)

## 常用的回归模型
- 线性回归
	- 可采用最小二乘或梯度下降等方法估计  LASSO等惩罚项
- 决策树
	- 决策树回归
    • 变量选择条件1:为每个变量选择切分点，从而将变量作为节点分裂
    • 变量选择条件2:在分裂后，依据相应分支内所有样本的因变量均值 作为估计，并评估拟合误差
    • 贪心策略:综合评价每个变量对上述两个条件的满足程度
    • CART回归树
- 随机森林
	• 集成学习之Bagging:随机选取样本、特征
  • 常采用决策树作为基模型
  • 并行集成策略
  • 取所有树的输出均值
- 梯度提升树:Gradient Boosting Tree、Xgboost、LightGBM、Catboost
  • 集成学习之Boosting:依据估计误差调整样本权重
  • 常采用决策树作为基模型
  • 串行集成策略
  • Gradient Booting Tree
  • Xgboost
  • LightGBM
  • Catboost
- Xgboost
  • 里程碑
  • Gradient Boosting算法的高效实现
  • 考虑了模型复杂度:在目标函数中添加了相关正则化项
  • 拟合效果更佳:对损失函数采用二阶泰勒展开
  • 多线程
  • .........
  • 近年来，被广泛应用于比赛、公司业务
- Lightgbm
  • 微软
  • 更快的训练速度
  • 更低的内存消耗
  • 功能更全面
  • 更新、维护好
  • 将连续型变量离散化后，采用直方图形式获取相应 统计量，寻求最优分割点(面试时常问)
-  Catboost
  • 采用特殊的方式处理类别型特征(建模时需指定)
  • 使用了组合类别特征
  • 基模型是对称树
  • 运行速度较慢(与CPU版的Xgboost类似
  
## 模型参数的设置
- 模型参数的设置
  • 不建议将精力放在调参;黔驴技穷时再调参
  • 仅需大体的设置主要参数即可
  • 例如，Xgboost，learning_rate=0.1，nround=200，max_depth=6
  
## 模型融合
  • 主要策略
  • 加权:算数平均数、几何平均数、调和平均数等
  • Stacking:交叉验证;类似于深度学习
  • Blending:简单划分数据集;相当于只做Stacking的一折
  • 模型平均
  	- 加权集成策略
  • 时序方法/模型与机器学习的融合
  • ........